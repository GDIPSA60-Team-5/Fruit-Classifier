# export_results.py  â€”â€”  è¿è¡Œå‰ç¡®ä¿å·² pip install pandas
import numpy as np, pandas as pd, datetime, zipfile, pathlib, shutil, os
import tensorflow as tf
from sklearn.metrics import confusion_matrix, classification_report

ROOT   = r'C:\Users\Cleveland\Desktop\mechanical\assignment5'
OUT    = pathlib.Path(ROOT, 'result')
BEST_W = OUT / 'best_stage2.weights.h5'   # â† è‹¥è„šæœ¬é€‰äº† stage1ï¼Œè¯·æ”¹å

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1  é‡æ–°æ„å»ºæ•°æ®é›† & æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IMG_SIZE = (224,224); BATCH=32
PREP = tf.keras.applications.efficientnet.preprocess_input

test_gen = tf.keras.preprocessing.image.ImageDataGenerator(
             preprocessing_function=PREP)
test_ds  = test_gen.flow_from_directory(
             pathlib.Path(ROOT,'test'), target_size=IMG_SIZE,
             batch_size=BATCH, shuffle=False)

CLASSES = list(test_ds.class_indices.keys())

base = tf.keras.applications.EfficientNetB0(
         include_top=False, input_shape=IMG_SIZE+(3,), weights=None)
model = tf.keras.Sequential([
    base, tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(len(CLASSES), activation='softmax')
])
model.load_weights(BEST_W)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2  é¢„æµ‹ & æŒ‡æ ‡è¡¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
y_true = test_ds.classes
y_prob = model.predict(test_ds, verbose=0)
y_pred = y_prob.argmax(axis=1)

cm   = confusion_matrix(y_true, y_pred)
rep  = classification_report(
         y_true, y_pred, target_names=CLASSES, output_dict=True)

# DataFrameï¼ˆæ¯ç±» + macro + weighted + accuracyï¼‰
rows  = CLASSES + ['macro avg','weighted avg']
data  = {k:[rep[k]['precision'], rep[k]['recall'], rep[k]['f1-score']]
         for k in rows if k in rep}
df    = pd.DataFrame(data, index=['precision','recall','f1']).T
df['support'] = [rep[k]['support'] for k in rows]

acc = np.mean(y_true == y_pred)
df.loc['accuracy (%)','f1'] = acc * 100

csv_path = OUT/'metrics_summary.csv'
df.to_csv(csv_path, float_format='%.4f')
np.save(OUT/'confusion_matrix.npy', cm)

print(f'âœ…  CSV saved to  {csv_path}')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3  æ‰“åŒ… ZIP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M')
zip_path  = OUT/f'results_{timestamp}.zip'
with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as z:
    # a) å›¾è¡¨ PNG
    for png in OUT.glob('F0*.png'):
        z.write(png, arcname=png.name)
    # b) æŒ‡æ ‡ CSV + NPY
    z.write(csv_path, arcname=csv_path.name)
    z.write(OUT/'confusion_matrix.npy', arcname='confusion_matrix.npy')
    # c) é”™è¯¯å›¾ç‰‡æ–‡ä»¶å¤¹ï¼ˆå¦‚æœæœ‰ï¼‰
    err_dir = OUT/'errors'
    if err_dir.exists():
        for p in err_dir.glob('*'):
            z.write(p, arcname=f'errors/{p.name}')

print(f'ğŸ“¦  All results zipped â†’ {zip_path}')
print('   ç°åœ¨å¯ç›´æ¥åœ¨èµ„æºç®¡ç†å™¨ä¸­å³é”®ä¸‹è½½æˆ–å¤åˆ¶ã€‚')
